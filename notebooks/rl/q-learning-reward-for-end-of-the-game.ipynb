{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this notebook is to implement q-learning with the reward for the end of the game (big negative reward for losing and some positive reward for winning) and test it using StockFish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:14.008935Z",
     "iopub.status.busy": "2024-11-21T17:20:14.008578Z",
     "iopub.status.idle": "2024-11-21T17:20:29.820404Z",
     "shell.execute_reply": "2024-11-21T17:20:29.819279Z",
     "shell.execute_reply.started": "2024-11-21T17:20:14.008905Z"
    },
    "id": "mjOvmXyn3VWa",
    "outputId": "5787b38f-bc8c-455d-ba3c-65e57114f698",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chess in /opt/conda/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: stockfish in /opt/conda/lib/python3.10/site-packages (3.28.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chess\n",
    "!pip install stockfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:29.822855Z",
     "iopub.status.busy": "2024-11-21T17:20:29.822531Z",
     "iopub.status.idle": "2024-11-21T17:20:29.829478Z",
     "shell.execute_reply": "2024-11-21T17:20:29.828579Z",
     "shell.execute_reply.started": "2024-11-21T17:20:29.822825Z"
    },
    "id": "kYsHR5-y3VWb",
    "outputId": "c56f5e78-52e1-43bc-f115-c8399792fdab",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import chess\n",
    "import chess.engine\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from stockfish import Stockfish\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Kaggle to train the model, so here are just some paths in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:29.830745Z",
     "iopub.status.busy": "2024-11-21T17:20:29.830488Z",
     "iopub.status.idle": "2024-11-21T17:20:30.194319Z",
     "shell.execute_reply": "2024-11-21T17:20:30.193620Z",
     "shell.execute_reply.started": "2024-11-21T17:20:29.830720Z"
    },
    "id": "AFipBS1d3VWc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "KAGGLE = True\n",
    "\n",
    "if KAGGLE:\n",
    "    input_stockfish_path = \"/kaggle/input/stockfish_ubuntu/other/default/1/stockfish-ubuntu-x86-64-avx2\"\n",
    "    stockfish_path = \"/kaggle/working/stockfish\"\n",
    "    if not os.path.exists(stockfish_path):\n",
    "        shutil.copy(input_stockfish_path, stockfish_path)\n",
    "    os.chmod(stockfish_path, 0o755)\n",
    "else:\n",
    "    stockfish_path = \"../../models/validation_stockfish/stockfish-windows-x86-64-avx2.exe\"\n",
    "\n",
    "stockfish = Stockfish(path=stockfish_path)\n",
    "stockfish.set_skill_level(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the Deep Q-Learning (DQN) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:30.197279Z",
     "iopub.status.busy": "2024-11-21T17:20:30.196640Z",
     "iopub.status.idle": "2024-11-21T17:20:30.205014Z",
     "shell.execute_reply": "2024-11-21T17:20:30.204088Z",
     "shell.execute_reply.started": "2024-11-21T17:20:30.197236Z"
    },
    "id": "-qwUYqEw3VWc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MaskLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        return torch.mul(x, mask)\n",
    "\n",
    "class ChessDQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessDQN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128*64, 128*64),  # Flattened input size for the chessboard\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128*64, 64*64)  # Output layer matches 64x64 move possibilities\n",
    "        )\n",
    "\n",
    "        self.mask_layer = MaskLayer()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        if mask is not None:\n",
    "            x = self.mask_layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the agent with the main q_learning() function which starts the training process with the use of deep q-learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:30.206735Z",
     "iopub.status.busy": "2024-11-21T17:20:30.206475Z",
     "iopub.status.idle": "2024-11-21T17:20:30.235559Z",
     "shell.execute_reply": "2024-11-21T17:20:30.234946Z",
     "shell.execute_reply.started": "2024-11-21T17:20:30.206711Z"
    },
    "id": "RIEyEHDo3VWd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ChessAgent:\n",
    "    def __init__(self, model_path=None):\n",
    "        self.epsilon = 0.9\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.gamma = 0.5 # Balance between immediate and long-term rewards\n",
    "        self.learning_rate = 1e-03\n",
    "        self.MEMORY_SIZE = 512 # how many steps to store for experience replay\n",
    "        self.MAX_PRIORITY = 1e+06 # max priority for a sample in memory. The higher the priority, the more likely the sample will be included in training\n",
    "        self.memory = []\n",
    "        self.batch_size = 10\n",
    "\n",
    "        self.policy_net = ChessDQN().to(device)\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            state_dict = torch.load(model_path, weights_only=True)\n",
    "            self.policy_net.load_state_dict(state_dict)\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def convert_board_to_bitarray(self, board):\n",
    "        \"\"\"\n",
    "        Convert the chess board state to a 3D bitarray.\n",
    "        \"\"\"\n",
    "        piece_bitboards = {\n",
    "            (chess.piece_symbol(pt).upper() if color else chess.piece_symbol(pt)): board.pieces_mask(pt, color)\n",
    "            for pt in chess.PIECE_TYPES for color in chess.COLORS\n",
    "        }\n",
    "        piece_bitboards['-'] = board.occupied ^ (2**64 - 1)\n",
    "        player = (2**64 - 1) if board.turn else 0\n",
    "        castling_rights = board.castling_rights\n",
    "        en_passant = 0\n",
    "        if board.ep_square is not None:\n",
    "            en_passant = 1 << board.ep_square\n",
    "\n",
    "        bitboards = list(piece_bitboards.values()) + [player, castling_rights, en_passant]\n",
    "        # convert each bitboard into a matrix 1 and 0\n",
    "        bitarray = np.array([[((bb >> i) & 1) for i in range(64)] for bb in bitboards]).reshape((16, 8, 8))\n",
    "\n",
    "        return bitarray\n",
    "\n",
    "    def get_move_index(self, move):\n",
    "        \"\"\"\n",
    "        Map a chess.Move object to a unique index.\n",
    "        \"\"\"\n",
    "        return 64 * (move.from_square) + (move.to_square)\n",
    "\n",
    "    def mask_valid_moves(self, board):\n",
    "        \"\"\"\n",
    "        Create a tensor mask of valid moves and a dictionary of move indices.\n",
    "        \"\"\"\n",
    "        mask = np.zeros((64, 64))\n",
    "        move_dict  = {}\n",
    "        for move in board.legal_moves:\n",
    "            mask[move.from_square, move.to_square] = 1\n",
    "            move_dict[self.get_move_index(move)] = move\n",
    "        return torch.from_numpy(mask.flatten()), move_dict\n",
    "\n",
    "    def select_action(self, board):\n",
    "        \"\"\"\n",
    "        Choose an action based on the current board state.\n",
    "        Use an epsilon-greedy strategy.\n",
    "        \"\"\"\n",
    "        bit_state = self.convert_board_to_bitarray(board)\n",
    "        valid_moves_tensor, legal_moves = self.mask_valid_moves(board)\n",
    "\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            chosen_move = random.choice(list(board.legal_moves))\n",
    "        else:\n",
    "            state_tensor = torch.tensor(np.array(bit_state), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            q_values = self.policy_net(state_tensor)\n",
    "            q_values = q_values.detach().cpu().numpy().flatten()\n",
    "            valid_q_values = q_values * valid_moves_tensor.numpy()\n",
    "            best_action_index = np.argmax(valid_q_values)\n",
    "            chosen_move = legal_moves.get(best_action_index, random.choice(list(board.legal_moves)))\n",
    "\n",
    "        return self.get_move_index(chosen_move), chosen_move, bit_state, valid_moves_tensor\n",
    "\n",
    "    def remember(self, priority, state, action, reward, next_state, done, valid_moves, next_valid_moves):\n",
    "        \"\"\"\n",
    "        Store a step in memory, ensuring it doesn't exceed maximum size.\n",
    "        \"\"\"\n",
    "        if len(self.memory) >= self.MEMORY_SIZE:\n",
    "            min_index = np.argmin([sample[0] for sample in self.memory])\n",
    "            del self.memory[min_index]\n",
    "        self.memory.append((priority, state, action, reward, next_state, done, valid_moves, next_valid_moves))\n",
    "\n",
    "    def adaptive_epsilon_decay(self):\n",
    "        \"\"\"\n",
    "        Reduce epsilon over time for less exploration.\n",
    "        \"\"\"\n",
    "        self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"\n",
    "        Save the model weights to a file.\n",
    "        \"\"\"\n",
    "        torch.save(self.policy_net.state_dict(), path)\n",
    "\n",
    "\n",
    "    def experience_replay(self):\n",
    "        \"\"\"\n",
    "        Perform experience replay to update the model's policy network using a prioritized replay buffer.\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        priorities = np.array([sample[0] for sample in self.memory])\n",
    "        probabilities = priorities / np.sum(priorities)\n",
    "\n",
    "        minibatch_indexes = np.random.choice(len(self.memory), size=self.batch_size, replace=False, p=probabilities)\n",
    "        minibatch = [self.memory[x] for x in minibatch_indexes]\n",
    "\n",
    "        states, state_valid_moves, actions, rewards, next_states, next_state_valid_moves, dones = [], [], [], [], [], [], []\n",
    "\n",
    "        for priority, bit_state, action, reward, next_bit_state, done, state_valid_move, next_state_valid_move in minibatch:\n",
    "            states.append(bit_state)\n",
    "            state_valid_moves.append(state_valid_move.unsqueeze(0))\n",
    "            actions.append([action])\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "\n",
    "            if not done:\n",
    "                next_states.append(next_bit_state)\n",
    "                next_state_valid_moves.append(next_state_valid_move.unsqueeze(0))\n",
    "\n",
    "        state_tensor = torch.tensor(np.array(states), dtype=torch.float32, device=device)\n",
    "        action_tensor = torch.tensor(np.array(actions), dtype=torch.int64, device=device)\n",
    "        reward_tensor = torch.tensor(np.array(rewards), dtype=torch.float32, device=device)\n",
    "        next_state_tensor = torch.tensor(np.array(next_states), dtype=torch.float32, device=device)\n",
    "        not_done_mask = torch.tensor(np.array([not done for done in dones]), dtype=torch.bool, device=device)\n",
    "        state_valid_tensor = torch.cat(state_valid_moves).to(device)\n",
    "        next_state_valid_tensor = torch.cat(next_state_valid_moves).to(device)\n",
    "\n",
    "        policy_q_values = self.policy_net(state_tensor, state_valid_tensor).gather(1, action_tensor)\n",
    "        with torch.no_grad():\n",
    "            next_q_values = torch.zeros(self.batch_size, dtype=torch.double, device=device)\n",
    "            next_q_values[not_done_mask] = self.policy_net(next_state_tensor, next_state_valid_tensor).max(1)[0]\n",
    "\n",
    "        target_q_values = reward_tensor + self.gamma * next_q_values\n",
    "        target_q_values = target_q_values.unsqueeze(1)\n",
    "\n",
    "        loss = self.loss_function(policy_q_values, target_q_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        priority = F.mse_loss(policy_q_values, target_q_values, reduction='mean').detach().cpu().numpy()\n",
    "        for idx, new_priority in zip(minibatch_indexes, priorities):\n",
    "            self.memory[idx] = (new_priority, *self.memory[idx][1:])\n",
    "\n",
    "        return float(loss)\n",
    "\n",
    "    def generate_random_sample(self, board):\n",
    "        \"\"\"\n",
    "        Generate a random sample for training by simulating a move.\n",
    "        \"\"\"\n",
    "        if not board.legal_moves:\n",
    "            return\n",
    "\n",
    "        priority = 1\n",
    "        state = self.convert_board_to_bitarray(board)\n",
    "        valid_moves, _ = self.mask_valid_moves(board)\n",
    "\n",
    "        random_move = random.choice(list(board.legal_moves))\n",
    "        action = self.get_move_index(random_move)\n",
    "        board.push(random_move)\n",
    "\n",
    "        if board.is_game_over() or not list(board.legal_moves):\n",
    "            reward = 10.0 if board.is_checkmate() else 3.0  # Final reward logic\n",
    "            done = True\n",
    "            next_state = self.convert_board_to_bitarray(board)\n",
    "            next_valid_moves = torch.zeros_like(valid_moves)  # No valid moves\n",
    "        else:\n",
    "            random_move_black = random.choice(list(board.legal_moves))\n",
    "            board.push(random_move_black)\n",
    "            next_state = self.convert_board_to_bitarray(board)\n",
    "            done = board.is_game_over()\n",
    "            next_valid_moves, _ = self.mask_valid_moves(board)\n",
    "            board.pop()\n",
    "\n",
    "            if board.is_checkmate():\n",
    "                reward = -10.0  # Loss for the agent\n",
    "            elif board.is_stalemate() or board.is_insufficient_material():\n",
    "                reward = 3.0  # Draw\n",
    "            else:\n",
    "                reward = 0.2  # Intermediate move\n",
    "\n",
    "        board.pop()\n",
    "        self.remember(priority, state, action, reward, next_state, done, valid_moves, next_valid_moves)\n",
    "\n",
    "    def game_result(self, board):\n",
    "        \"\"\"\n",
    "        Determine the game result.\n",
    "        \"\"\"\n",
    "        if board.is_checkmate():\n",
    "            return 1 # Win\n",
    "        elif board.is_stalemate() or board.is_insufficient_material():\n",
    "            return 0 # Draw\n",
    "        else:\n",
    "            return -1 # Loss\n",
    "\n",
    "    def play_single_game(self, board, max_moves):\n",
    "        \"\"\"\n",
    "        Simulate a single game for training.\n",
    "        \"\"\"\n",
    "        done, game_moves, game_loss = False, 0, []\n",
    "\n",
    "        while not done and game_moves < max_moves:\n",
    "            action_index, chosen_move, bit_state, valid_moves_tensor = self.select_action(board)\n",
    "            board.push(chosen_move)\n",
    "            self.generate_random_sample(board)\n",
    "            loss_value = self.experience_replay()\n",
    "            if loss_value is not None:\n",
    "                game_loss.append(loss_value)\n",
    "            done = board.is_game_over()\n",
    "            game_moves += 1\n",
    "\n",
    "        return sum(game_loss) / len(game_loss) if game_loss else 0.0, self.game_result(board)\n",
    "\n",
    "    def q_learning(self, games_to_play, max_game_moves, board_config=None):\n",
    "        \"\"\"\n",
    "        Train the agent using Q-learning.\n",
    "        \"\"\"\n",
    "        loss, final_score, steps = [], [], 0\n",
    "\n",
    "        for _ in tqdm(range(games_to_play), desc=\"Training Games\"):\n",
    "            board = chess.Board() if board_config is None else chess.Board(board_config)\n",
    "            game_loss, result = self.play_single_game(board, max_game_moves)\n",
    "            loss.append(game_loss)\n",
    "            final_score.append(result)\n",
    "            self.adaptive_epsilon_decay()\n",
    "\n",
    "        return pd.DataFrame({\"Loss\": loss, \"Score\": final_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing how the agent class works on 10 random board samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:30.236821Z",
     "iopub.status.busy": "2024-11-21T17:20:30.236524Z",
     "iopub.status.idle": "2024-11-21T17:20:31.841349Z",
     "shell.execute_reply": "2024-11-21T17:20:31.840449Z",
     "shell.execute_reply.started": "2024-11-21T17:20:30.236796Z"
    },
    "id": "mx3Tv3-d3VWd",
    "outputId": "23d7d1d5-1fa9-4200-beae-4f339504ee4c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "board = chess.Board()\n",
    "agent = ChessAgent()\n",
    "\n",
    "for i in range(10):\n",
    "    agent.generate_random_sample(board)\n",
    "\n",
    "loss = []\n",
    "for i in range(10):\n",
    "    loss.append(agent.experience_replay())\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is dropping significantly, let's train an agent on the bigger number of games:\n",
    "1000 epochs with the batch size of 10 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:20:31.842706Z",
     "iopub.status.busy": "2024-11-21T17:20:31.842415Z",
     "iopub.status.idle": "2024-11-21T17:56:57.765377Z",
     "shell.execute_reply": "2024-11-21T17:56:57.764484Z",
     "shell.execute_reply.started": "2024-11-21T17:20:31.842678Z"
    },
    "id": "OESca2YK3VWe",
    "outputId": "6f5f9c98-4515-4355-cb59-f1c6e8c71f1c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Games: 100%|██████████| 1000/1000 [36:25<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "df = agent.q_learning(games_to_play=1000, max_game_moves=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:56:57.768106Z",
     "iopub.status.busy": "2024-11-21T17:56:57.767496Z",
     "iopub.status.idle": "2024-11-21T17:56:57.778676Z",
     "shell.execute_reply": "2024-11-21T17:56:57.777673Z",
     "shell.execute_reply.started": "2024-11-21T17:56:57.768076Z"
    },
    "id": "OESca2YK3VWe",
    "outputId": "6f5f9c98-4515-4355-cb59-f1c6e8c71f1c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.011023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.007552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.003787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.002382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.009095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.002806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.000696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.001676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0.001857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.003204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0.000623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Loss  Score\n",
       "7    0.020946      1\n",
       "28   0.011023      1\n",
       "53   0.007552      1\n",
       "139  0.003787      1\n",
       "145  0.002382      1\n",
       "319  0.009095      1\n",
       "496  0.000868      1\n",
       "501  0.002806      1\n",
       "678  0.000696      1\n",
       "685  0.001676      1\n",
       "739  0.003097      1\n",
       "785  0.001857      1\n",
       "811  0.003204      1\n",
       "848  0.000623      1\n",
       "886  0.000615      1\n",
       "975  0.000366      1\n",
       "984  0.000225      1\n",
       "989  0.000238      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_rows = df[df['Score'] != -1]\n",
    "non_zero_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that loss became smaller than it was initially, but the agent won only a few games against randomly-acting opponent.\n",
    "Now, let's test our agent on different StockFish levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T18:06:18.230021Z",
     "iopub.status.busy": "2024-11-21T18:06:18.229554Z",
     "iopub.status.idle": "2024-11-21T18:06:18.234058Z",
     "shell.execute_reply": "2024-11-21T18:06:18.233137Z",
     "shell.execute_reply.started": "2024-11-21T18:06:18.229988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_agent = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T18:06:21.011134Z",
     "iopub.status.busy": "2024-11-21T18:06:21.010830Z",
     "iopub.status.idle": "2024-11-21T18:10:31.516453Z",
     "shell.execute_reply": "2024-11-21T18:10:31.515514Z",
     "shell.execute_reply.started": "2024-11-21T18:06:21.011109Z"
    },
    "id": "3XK_mOPi3VWg",
    "outputId": "c754f465-ca09-4d1c-a074-a26538287306",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stockfish level: 1: {'Wins': 0, 'Losses': 13, 'Draws': 7, 'Win Rate': 0.175, 'Stockfish Level': 1}\n",
      "Stockfish level: 5: {'Wins': 0, 'Losses': 12, 'Draws': 8, 'Win Rate': 0.2, 'Stockfish Level': 5}\n",
      "Stockfish level: 10: {'Wins': 0, 'Losses': 15, 'Draws': 5, 'Win Rate': 0.125, 'Stockfish Level': 10}\n",
      "Stockfish level: 15: {'Wins': 0, 'Losses': 18, 'Draws': 2, 'Win Rate': 0.05, 'Stockfish Level': 15}\n"
     ]
    }
   ],
   "source": [
    "def configure_stockfish_using_skill_level(skill_level):\n",
    "    stockfish = Stockfish(path=stockfish_path)\n",
    "    stockfish.set_skill_level(skill_level)\n",
    "    return stockfish\n",
    "\n",
    "def configure_stockfish_using_rating(elo_rating):\n",
    "    stockfish = Stockfish(path=stockfish_path)\n",
    "    stockfish.set_elo_rating(elo_rating)\n",
    "    return stockfish\n",
    "\n",
    "def play_single_stockfish_game(agent, stockfish, max_moves=50):\n",
    "    board = chess.Board()\n",
    "    stockfish.set_fen_position(board.fen())\n",
    "\n",
    "    for move_count in range(max_moves):\n",
    "        if board.turn:\n",
    "            _, move, _, _ = agent.select_action(board)\n",
    "        else:\n",
    "            move = chess.Move.from_uci(stockfish.get_best_move())\n",
    "        board.push(move)\n",
    "        stockfish.set_fen_position(board.fen())\n",
    "\n",
    "        if board.is_game_over():\n",
    "            break\n",
    "\n",
    "    return board.result()\n",
    "\n",
    "def evaluate_agent(agent, skill_levels, games_per_rating=20):\n",
    "    results = []\n",
    "\n",
    "    for level in skill_levels:\n",
    "        stockfish = configure_stockfish_using_skill_level(level)\n",
    "        outcomes = {\"Wins\": 0, \"Losses\": 0, \"Draws\": 0}\n",
    "\n",
    "        for _ in range(games_per_rating):\n",
    "            result = play_single_stockfish_game(agent, stockfish)\n",
    "            if result == \"1-0\":\n",
    "                outcomes[\"Wins\"] += 1\n",
    "            elif result == \"0-1\":\n",
    "                outcomes[\"Losses\"] += 1\n",
    "            else:\n",
    "                outcomes[\"Draws\"] += 1\n",
    "\n",
    "        win_rate = (outcomes[\"Wins\"] + 0.5 * outcomes[\"Draws\"]) / games_per_rating\n",
    "        outcomes[\"Win Rate\"] = win_rate\n",
    "        outcomes[\"Stockfish Level\"] = level\n",
    "        results.append(outcomes)\n",
    "\n",
    "        print(f\"Stockfish level: {level}: {outcomes}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "stockfish_skill_levels = [1, 5, 10, 15]\n",
    "results = evaluate_agent(test_agent, stockfish_skill_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, agent performance is very low now.\n",
    "It could be because of the overfitting, but as we can see from the epochs on which it was winning, it is not the case. I guess that it is just not a good algorithm to use for chess\n",
    "(We tried other parameters and different combinations of layers in this notebook, but the results were almost the same)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q-learning-mate-reward",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 168146,
     "modelInstanceId": 145576,
     "sourceId": 171063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
